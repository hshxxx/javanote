# 操作系统

## 一、引论和硬件基础



### 1. 概述：

系统资源的管理者，负责对计算机的软硬件资源进行控制和管理，解决系统中各程序对资源使用请求的冲突，保证各个程序顺利完成。

- 主要功能： **进程与处理机**管理，**作业**管理，**存储**管理，**设备**管理，**文件**管理 
- 主要特点：**并发**（最基本），共享，虚拟，异步

### 2. 分类

- 批处理操作系统：
  - **作业**存储在后备队列中，成**批**送往内存中处理。
  - 多道批处理系统能交替使用CPU，所以**提高了CPU的利用率**，但**延长了作业周转时间**，**不利于用户交互**
  - **周转时间短**作为性能指标： 从一个批处理**作业提交时刻开始**直到该**作业完成时刻为止**的统计的**平均时间** 
- 分时操作系统：
  - CPU的使用被分为**时间片**，按时间片轮流服务
  - **响应时间比**作为性能指标： 作业等待时间+作业计算时间 
- 实时操作系统：
  - 规定时刻前完成任务，否则造成**硬损伤**。
  - **截止时间的保证**作为性能指标
- 网络操作系统
  - 管理网络通信和共享资源
- 分布式操作系统
  - 将任务分配到多台处理机上运行，通过合理调度，提高并行度

### 3. 接口：用户通过接口调用os的服务

- 命令接口CLI
- 程序接口API
- 图形接口GUI



### 4. 内核

- 单体结构：整个系统以单一程序运行，以**程序集合**组成。每个**系统调用**对应一个**服务程序**来执行，同时还有一个**实用程序**来弥补服务程序所需要的功能。
- 层次结构：降低耦合性
- 微内核结构：OS分为若干小的**模块**，只有一个**微内核**模块运行在**内核态**，其余模块被当做**用户态**的**进程**。用户态分为三层，由上到下分别为：**用户程序层**，**服务器层**，**驱动程序层**。因为用户态不能物理访问IO端口空间，发送IO命令，所以驱动器构造了一个结构，指明哪个参数值写到哪个IO端口，并声称一个内核调用，完成一次内核调用。

### 5. 中断

- 强迫性中断：不是程序所期待的
  -  输入输出中断 
  -  外中断 
  -  机器故障中断 
  -  程序性中断 ： 运行程序本身的中断，如 溢出、缺页中断、缺段中断、地址越界 
- 自愿性中断：程序所期待的
  -  访管中断：用户程序在用户态（目态）下希望OS在内核态（管态）为其提供服务引起的中断

### 6.多任务处理和多重处理

- 多任务处理： cpu频繁切换，轮流为各个进程提供服务，似乎在同时处理多个任务，我们称之为多任务，实际上任一时刻cpu只为一个进程提供服务 
- 多重处理：对于有**多个CPU**的计算机系统，同时在**每个CPU上处理进程**，实际上是多任务多重处理

--------------------------

### 1. 处理器系统

- 特权指令：在进程调度时可以使用，即内核态下可以使用，一般不给用户使用
- 非特权指令：用户可以使用

1.1 处理器指令

- 操作码：操作类型

- 源操作数：输入

- 目的操作数：结果
- 下一条指令地址：

1.2 寻址方式：两种方式交替进行，**先一次**指令，**后多次**数据

- 指令寻址方式
  - 顺序寻址方式
    - 指令顺序存储在内存中，每执行一次，程序计数器PC加一，用PC的值寻找下一跳指令地址
  - 跳跃寻址方式
    - 下一条指令地址由正在执行中的指令给出
- 数据寻址方式
  - 隐含寻址
  - 立即寻址
  - 直接寻址
  - 间接寻址
  - 寄存器寻址和寄存器间接寻址
  - 相对寻址：下一个指令地址 = 程序计数器 + 地址偏移量
  - 基址寻址：下一个指令地址 = 基址寄存器 + 变址寄存器
  - 变址寻址：下一个指令地址 = 变址寄存器 + 偏移量
  - 块寻址

1.3 寄存器

1.4 内存屏障

-  也称内存栅栏， 是一类同步屏障指令，内存屏障之前的所有写操作都要写入内存；内存屏障之后的读操作都可以获得同步屏障之前的写操作的结果。因此，对于敏感的程序块，写操作之后、读操作之前可以插入内存屏障。 使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作。  
- 计算机为了提高性能而采取乱序执行，内存屏障可以防止出错
-   分类：读屏障、写屏障、通用屏障、优化屏障
   - **读屏障**之前的读操作一定会先于屏障之后的读操作完成，写操作不受影响，**写屏障**用于限制写操作，对读操作不限制。
   - 而**通用屏障**则对读写操作都有作用。
   -  而**优化屏障**则用于限制编译器的指令重排，不区分读写。前三种屏障都隐含了优化屏障的功能。 

### 2. 存储系统

- CPU内寄存器
- 高速缓存：Cache L1、 L2、 L3（静态随机存储器SRAM技术)
  - 高速存储器
    - 按照内存的划分形式划分为若干行和列，但**行数比内存少**。
  - 联想存储器
    - 与高速存储器有相同行数和列数
    - 当调用内存中某一存储单元组到高速存储器中**同一列某行**时，联想存储器在和高速存储器相同位置存储该单元组在内存中的**行号**。
    - 当处理器存取内存时，硬件先对存取地址的**列译码**，在联想存储器中寻找该列下是否有存取地址**所在行**，若存在则称为命中，反之称为失效，并将对应行对应列的存储单元组存入高速存储器，在联想存储器写入相应行 
  - 置换逻辑电路和控制线路
    - 根据所采用置换算法，置换高速存储器中相应页面
  - 内存地址和缓存地址间的对应关系
    - 全相联：内存任意一块可以映射到缓存中任意一块
    - 直接相联：将内存划分成区，每个区大小和缓存大小一致，内存中每个区中的块只能对应缓存中特定的一块
    - 组相联：缓存中按组划分成大小相等的若干组，内存中按缓存整体大小划分成若干区，每个区的大小和缓存大小一致，内存中某一区的某一组对应缓存中某一组，组之间可任意对应。
- 内存：DRAM
  - 被划分为若干**行**，每行划分为若干**列**，一行一列确定一个**存储单元组**，每组长若干字节
  - ROM：只能读不能写，停电后数据不会丢失，如存储BIOS ROM 用来启动电脑
  - RAM：可读可写，停电后数据丢失
  - 存储地址空间大小（编址空间） **>** 物理存储器（实际空间）
- 外存：
- 中断
  - 可屏蔽
  - 不可屏蔽
  - 陷入机制：用户态--> 系统态 后，在系统态下处理中断 



## 二、进程，线程-->CPU调度

### 1.综述

- 程序：一组指令的静态集合，静态的，必须一次执行完不能中断
- 进程：一个程序在一个数据集合上的一次运行过程，动态的，可以中断，所以支持并发执行
  - 进程映像：进程实体组成
    - 可执行的程序 +  有关数据集 + 进程控制块PCB + 用户栈 + 内核栈
    - 进程控制块PCB是OS感知进程**唯一标识**，只能有OS修改，进程自己不能修改
  - 进程状态
    - 创建状态：正在创建但还没完成，尚未加入就绪队列
    - 就绪状态：就差获得CPU了，在就绪队列中排队
    - 运行状态：正在CPU上运行
    - 阻塞状态：等待其他资源释放或事件完成
    - 终止状态：正常结束 或 出现不能克服的错误
    -  ![img](https://uploadfiles.nowcoder.com/images/20190308/1596072_1552009733393_E6DE6171C18BA10061A484453831AAE3) 
    - 在内存中叫**活动态**，在外存中叫**静止态**
      - 调度程序会将很久未使用的进程调到外存上
  - 分类
    - 孤儿进程
      - **父进程退出时，子进程还未退出**，那么子进程被托孤给**init进程**，init成为其父进程，同时**init进程没有父进程**
      - 所以父进程撤销时子进程不一定也撤销
    - 僵尸进程
      - 进程已经终止，但因为还需要等待告知父进程自己的状态，所以暂时不被撤销
  - 进程上下文：保存的是进程的状态 ，进程重新运行时恢复的就是进程上下文中内容
  - 特性
    - 并发性：指多个进程实体同存于内存中，且在一段时间内同时运行。并发性是进程的重要特征，同时也成为操作系统的**重要特征**。
    - 动态性：进程的实质是进程实体的一次执行过程，因此，动态性是进程**最基本的特征**。
    - 独立性：进程实体是一个独立运行、独立分配资源和独立接受调度的基本单位。
    - 异步性：指进程按各自独立的、不可预知的速度向前推进，或者说实体按异步方式运行。
  - OS何时创建进程
    - 1 用户登录：系统为用户创建一个进程，并插入就绪队列
      2 作业调度
      3 提供服务 ：系统为用户请求创建一个进程
      4 应用请求 ：用户程序自己创建进程

### 2.进程控制



### 3.进程同步

- 进程同步：一个任务可能由几个线程共同完成，这几个线程间需要相互协调着运作。比如，当缓冲区为空时，读进程被阻塞，只有写进程完成后读进程才能继续。

#### 3.1 基本概念

- 临界资源 Critical resource：一次只允许被一个进程使用的共享资源，如CPU，IO设备，实现**进程的互斥**

- 临界区 CriticalSection ：进程中访问临界资源的**代码**

  - ```java
    do{
        进入区: 检查临界资源
        临界区：访问临界资源
        退出区：设置临界资源
        剩余区：无关代码
    }while(true)
    ```

    

- 同步机制应遵循的原则

  - 空闲让进
  - 忙则等待
  - 有限等待
  - 让权等待：进城不能进入临界区时，应立即释放CPU

#### 3.2 解决进程同步机制

-  事件、临界区、互斥量、信号量可以实现进程和线程的同步 
   -  事件：
      - 事件机制，则允许一个线程在处理完一个任务后，主动唤醒另外一个线程执行任务。
      - 比如在某些网络应用程序中，一个线程如A负责侦听通信端口，另外一个线程B负责更新用户数据，利用事件机制，则线程A可以通知线程B何时更新用户数据。每个Cevent对象可以有两种状态：有信号状态和无信号状态。Cevent类对象有两种类型：人工事件和自动事件。
        　　自动事件对象，在被至少一个线程释放后自动返回到无信号状态；
          　　人工事件对象，获得信号后，释放可利用线程，但直到调用成员函数ReSet()才将其设置为无信号状态。在创建Cevent对象时，默认创建的是自动事件。
   -  互斥量
      -  互斥对象和临界区对象非常相似，只是其允许在进程间使用，而临界区只限制与同一进程的各个线程之间使用

3.2.1 利用硬件

- 禁止中断：单处理器适用

- 利用专用机器指令

  - TSL指令

    - ```java
      boolean TSL(boolean *lock){ //lock 全局变量， false表示资源空闲
          boolean old;
          old=*lock;
          *lock=TRUE;
          return old;
      }
      
      do{
          while(TSL(&lock));
          临界区
          lock=FALSE;
          剩余区
      }while(TRUE);
      ```

  - Swap指令

    - ```java
      void Swap(boolean *a, boolean *b){
          boolean temp;
          temp=*a;
          *a=*b;
          *b=temp;
      }
      
      do{
          boolean key=TRUE;
          while(key==TRUE)
              Swap(&lock,&key);
          临界区
          lock=FALSE;
          剩余区
      }while(TRUE);
      ```

3.2.2 利用软件

- Peterson算法：双进程互斥
- 面包店算法

3.2.3 利用锁机制：进入临界区上锁，退出开锁，上锁和开锁是两个原语

3.2.4 利用信号量机制：

```java
信号量S表示可用临界资源的数量
wait()表示进程申请某临界资源，signal()表示进程释放某临界资源
```

- 整形信号量机制
  - wait就是申请资源，signal就是释放资源
  - 在wait()（P操作）方法中先执行S--，若S>=0，那么该进程继续执行，若S<0，那么该进程阻塞
  - 在signal()（V操作）方法中先执行S++，若S>0，那么该进程继续执行，若S<=0，那么唤醒一个阻塞进程，让其加入就绪队列中
- 记录型信号量机制
  - 结构体型信号里量S包含：一个**整型变量value**，一个指向对应阻塞队列的**指针**，一个**阻塞队列**
  - 在wait()方法中先信号量S.value--，若S.value>=0，进程继续执行，反之，进城被加入到阻塞队列中
  - 在signal()方法中先信号量S.value++，若S.value>0，进城继续执行，反之，从阻塞队列中唤醒队首进程
- 信号量集机制：多个资源
  - 将进程生命周期中所需的所有资源一次性分配，最后一次性释放
  - 一个资源没有申请成功，则其他资源都释放

3.2.5 利用信号量解决同步互斥问题思考步骤

- 确定进程：进程数量，进城工作内容
- 确定进程间同步互斥关系：使用临界资源--->互斥， 进程相互合作，有前后执行顺序--->同步
- 设置信号量：确定 互斥/ 同步 信号量的个数，含义，初始值以及对信号量的wait() / signal() 操作
- 用伪代码描述

#### 3.3 经典进程同步问题

- 生产者--消费者问题
  - m个生产者，n个消费者，共享长为k的循环缓冲池
- 哲学家进餐问题
- 读者--写者问题
- 理发师问题

#### 3.4 管程机制

3.4.1 概述

- 管程过程中的操作是**原子操作**，进程应互斥地使用管程，在使用管程时**不可被中断**。

- 需要编译器支持的进程同步机制，把分散在各进程中的相关临界区集中起来由系统统一管理并实现同步
- 一个管程定义一个数据结构和并发进程在该数据结构上可以执行的操作，数据结构是对系统中软硬件资源的抽象描述，同时存储一组过程，每个过程完成进程对数据结构的某种操作。

3.4.2 条件变量

- 用来实现进程间同步关系
- 一个条件变量代表进程继续执行多需要的一个条件，通常对应一个等待队列



--------------------

### 4. 进程调度

4.1 基本概念

4.1.1 调度层次

- 高级调度
  - 频率低
  - 从**外存**的**后备队列**中选若干作业，为其创建进程，并插入**内存**中的**就绪队列**
- 低级调度
  - 就绪队列中选某个进程，给其分配CPU
- 中级调度
  - 内存中不能运行的进程换出到外存，该进程成为挂起进程，内存空间充裕时，又将挂起进程调入内存中

4.1.2 调度方式

- 非抢占式
- 抢占式：根据时间片，优先级，进程运行时间等来分配
  - 内核完全不可抢占：内核态下完全不能被抢占
  - 内核部分可抢占：
  - 内核完全可抢占

4.1.3 调度性能指标：CPU利用率，系统吞吐量，周转时间和带权周转时间

4.2 调度算法

- **先来先服务** FCFS：作业，进程调度都适合；有利于长作业，不利于短作业
  - 将驻留时间最久的作业调入内存，或给驻留时间最久的进程分配CPU
  - **作业周转时间  =  完成时间 -  提交时间**
  - **带权周转时间 =  周转时间  /  要求执行时间**
- **短作业优先** SJF： 作业，进程调度都适用； 能获得**最短的作业平均周转时间**
  - 将若干估计运行时间最短的作业调入内存，或给估计运行时间最短的进程分配CPU
  -  让平均等待时间最短，也就是让**同时等待的任务最少**，也就是尽快地完成任务，所以小任务优先，就可以让等待的任务尽快减少 
- **高响应比优先** HRRF：作业，进程调度都适用； 照顾短作业或短进程，但不能保证紧迫型任务及时处理
  - **响应比** = 1 +  等待时间 / 要求服务时间  ；    越高优先级越高
- **优先级调度**：进城调度使用
- **时间片轮转 RR**：分时系统中的进程调度适用
- **多级队列调度**：进程调度使用
  - 就绪队列分为多个独立队列
  - 每个队列有自己独立的调度算法
    - 实时进程队列采用抢占式优先级调度
    - 系统进程队列采用非抢占式优先级调度
    - 交互式进程队列采用时间片轮调度
    - 批处理进程队列采用先来先服务或短作业优先调度
  - 各队列间优先级不同
  - 根据进程的属性将进程永久地分配到一个固定队列中
- **多级反馈队列调度**： 进程调度适用
  - 设置多个就绪队列
    - 各个队列优先级不同，从第一个开始逐次降低，优先级越高时间片最短
  - 各**队列内部**按**时间片**轮转算法
    - 若时间片结束时还未完成，则插入下一个队列末尾排队，最后一个队列不再降级
  - 各**队列间**采用抢占式**优先级**调度、
    - 第一个队列为空时才调度第二个队列中进程
    - 若当前队列之前的队列中插入新的进程，则中断当前进程，执行优先级最高的进程
  - 提升在低优先级队列中等待时间很长的进程的优先级

-------------------------

### 5.进程通信

#### 5.1通信类型

5.1.1 共享存储系统通信：linux采用该方法

- 在内存中划出一片共享存储区，每个进程通信时向系统申请一个其中的一个分区，进程将该分区映射到自己的地址空间中便可进行通信

5.1.2 消息传递系统通信

- 直接通信
  - OS实现一对通信原语send() 和 receive()
  - 一般采用无阻塞发送，阻塞接收
- 间接通信
  - 一个成为**信箱**的数据结构，由信箱头和信箱体组成，也叫做**消息队列**，**单向**
  - 信箱头存放有关信箱的描述，信箱体存放信件

5.1.3 管道通信： 两个进程间通信； linux采用，**单向字符数据流**，可以有多个进程进行读写操作，读写操作要互斥同步，同一时刻只能一个进程读写，写完之后要阻塞自己，等待其他进程读之后才能被唤醒

- 管道用来将一个共享的**管道文件**的两头分别连接到两个进程上
- 无名管道：高速缓存中的临时文件，关闭管道后管道文件消失
- 有名管道：任意进程间通信，管道文件长期存在

5.1.4 客户-服务器通信：socke套接字通信，同一台计算机上也可以用本地环路通信（本地socket）

5.1.5 linux的进程通信方式

- 管道pipe，信号signal，报文队列，共享内存，信号量 semaphore ，Unix套接字

#### 5.2 消息缓冲队列通信机制

- 直接通信的一种具体实现
- 发送进程--->发送区--->消息缓冲区--->接受进程的消息队列--->消息缓冲区--->接受区--->接受进程
- 所用数据结构
  - 消息缓冲区
  - 缓冲区队列
  - PCB

### 6. 进程死锁

6.1.1 概念：无休止等待对方释放手中资源

6.1.2 产生死锁原因

- 竞争资源
  - 可重用资源
    - 可剥夺资源
    - 不可剥夺资源：对不可剥夺资源的竞争可能导致死锁发生
  - 消耗性资源
- 进程推进顺序不当

6.1.3 产生死锁条件

- 互斥条件：资源在一段时间只能由一个进程占有
- 占有且等待条件：已至少占有一个资源，同时申请其他资源
- 不可剥夺条件：不可剥夺资源只能被当前进程释放，其他进程不能强行剥夺
- 循环等待条件：若干进程间形成循环等待

6.1.4 处理死锁的方法

- 预防死锁
  - 破坏占有且等待条件：进程释放已占有资源后才可申请新的资源
  - 破坏不可剥夺条件：进程申请新资源不能立刻满足时，已占有资源可以被其他进程剥夺； 适用于可剥夺资源
  - 破坏循环等待条件：根据大部分进程对资源类型的使用顺序进行排序，生命周期中按递增顺序申请资源
- 避免死锁
  - 安全状态：判断进程申请资源后是否进入不安全状态
    - 进程序列p1--pi--pn，pi还需要的资源可以通过现有空闲资源 + 所有 pj (j<i) 已占有资源来满足，称此刻为安全状态，称p1--pi--pn 为安全序列
  - 银行家算法
    - 所需数据结构
      - 进城数目 n, 资源种类数目 m
      - 可利用资源向量 Available：长为m的向量，Avaliable[i] =k 表示第i个资源当前可用数量为k个
      - 最大需求矩阵 Max：一个n × m 的矩阵， Max[i] [j] = k  表示进程Pi 对 Rj类资源的最大需求数量是k个
      - 分配矩阵 Allocation：一个n × m 的矩阵，Allocation[i] [j] = k  表示进程pi当前已经分配到k个Rj类资源
      - 需求矩阵 Need：一个n × m 的矩阵，Need[i] [j] = k 表示进程Pi还需要k个Rj类资源
      - 
    - 安全性算法
      - 步骤1：初始化向量
        - 工作向量 Work：长度为m, 某时刻能提供的各类资源的可用数量，初始值为Available
        - 布尔向量 Finish： 长度为n，是否有足够资源分配给进程，初始值为False
      - 步骤2：从进程集合中寻找同时满足 Finish[i] = False,   Need [i] [j] <= Work[j]  的进程；若找到执行步骤3，没找到执行步骤4 
      - 步骤3：Pi获得所需资源后顺利执行，直至完成并释放所占资源  Work = work + Alloction[i],   Finish[i] = True； 返回步骤2
      - 步骤4：对**所有i** (0,1,...,n-1)， Finish[i] = True； 判定的当前系统处于安全状态，反之为不安全状态
    - 银行家算法
      - 步骤1：初始化向量
        - Requesti：长度为m，Requesti [j] = k 表示Pi请求k个 Rj 类资源 
      - 步骤2： 若 Requesti <= Need i ，执行步骤3， 反之出错返回
      - 步骤3：若 Requesti <= Available，执行步骤4， 反之Pi等待
      - 步骤4：Available = Available - Requesti， Allocationi = Allocationi + Requesti，Needi = Needi - Requesti;
      - 步骤5：在步骤4的基础上执行安全性算法，若安全则分配，反之进程Pi 阻塞等待
- 检测死锁
  - 允许进程同台申请资源，进行资源分配时不检查分配安全性
  - 资源分配图：描述资源分配情况，圆圈表示进程，方框表示一类资源
  - 死锁定理：当前时刻的资源分配图是不可完全简化的
    - 步骤1：从资源分配图中找出一个既不阻塞又非独立的进程Pi，若找到执行步骤2，反之执行步骤3
    - 步骤2：消去Pi的所有资源请求边和分配边，返回步骤1
    - 步骤3：所有进程结点都成为独立节点，称当前资源分配图是可完全简化的，反之是不可完全简化的。**不可完全简化的资源分配图**是有可能导致**死锁**的**充分非必要条件**，不安全状态下只要资源分配得当就不会出现死锁
  - 死锁检测算法
    - 所需数据结构
      - 可利用资源向量 Available，长度为m，描述每类资源当前可分配数量
      - 分配矩阵 Allocation，一个n × m 的矩阵，描述当前各进程已经分配到的各类资源数量
      - 资源请求矩阵Request，一个n × m 的矩阵，描述当前各进程对各类资源的请求数量
    - 步骤1：初始化向量
      - 工作向量 Work：长度为m, 某时刻能提供的各类资源的可用数量，初始值为Available
      - 布尔向量 Finish： 长度为n，是否有足够资源分配给进程，初始值为False
    - 步骤2：寻找同时满足 Finish[i] = False, Requesti <= Work 条件的进程，若找到执行步骤3，反之执行步骤4
    - 步骤3：执行 Work = work + Alloction[i],   Finish[i] = True；然后转回步骤2 
    - 步骤4：若所有 Finish[i] = true，则系统没有发生死锁，否则Finish[i] = False 表示进程Pi死锁
  - 死锁检测时机
    - 周期性定时检测
    - 依据CPU利用率：设定一个阈值，低于阈值时就进行死锁检测
- 解除死锁
  - 撤销所有死锁进程
  - 抢占资源
    - 人工逐步抢占部分死锁进程的资源给其他进程使用

### 7. 线程机制

#### 7.1 基本概念

- 轻量级进程，依附于进程存在和运行，可以并发执行
- 进程是资源分配的基本单位，线程是调度的基本单位
- 多进程处理一个客户请求会耗费大量系统资源，所以提出多线程处理一个客户请求，提高系统响应的同时降低对系统资源的占用
- 线程ID + 一组寄存器集合 + 用户栈 + 内核栈 + 私有存储区 + 线程控制块TCB
- 线程**共享进程的堆和方法区**，每个线程又拥有自己的程序计数器，虚拟机栈和本地方法栈。
  - 为什么线程共享进程的堆和方法区
    - **堆**是进程中最大的一块内存，主要用于存放**新创建的对象** (所有对象都在这里分配内存)，方法区主要用于存放已被加载的**类信息**、常量、静态变量、即时编译器编译后的代码等数据。
  - 为什么线程要私有程序计数器？
    - 程序计数器用来存储下一条指令的位置，线程是并发运行的所以需要记录线程执行的位置，保证**线程切换后能恢复到正确的执行位置**
  - 为什么线程要私有虚拟机栈和本地方法栈？
    - **保证线程中的局部变量不被别的线程访问到**
- 调度，通信，互斥同步与进程一致，线程间通信在**用户态**即可进行
- OS调度的基本单位，单个线程崩溃时整个进程会退出
- 同一进程内的线程共享同一地址空间
- 因为**线程在同一地址空间**，所以线程之间通信速度，切换速度**更快**，内存利用率**更好**，还需要使用**同步**机制

#### 7.2 线程实现机制

- 用户级线程 ULT：用户空间中实现
  - 共享存储区的线程----用户线程
  - 线程库： 一组应用程序代码，支持线程的创建，撤销，同步，通信等操作
  - 私用线程表：每个进程都有该表，记录该进程下所有线程情况
  - 缺点
    - 线程的阻塞会导致进程的阻塞
    - 不能利用多处理器优势
- 内核级线程 KLT：内核空间中实现
  - 没有私有存储区的线程---内核线程
  - 进程表：内核中有一个进程表记录系统中所有进程的信息
  - 线程表：内核中有一个线程表记录系统中每个线程的信息
  - 优点
    - 线程阻塞只影响自己，不阻塞进程
    - 一个进程中的多个线程可以在多个CPU上并行运行
- 组合使用方式：用户级线程 与 内核级线程的映射关系
  - 多对一：一个进程中的多个用户级线程映射到一个内核级线程上，一个线程阻塞则整个进程阻塞
  - 一对一：一个用户级线程映射到一个内核级线程上，开销较大，需要限制线程数
  - 多对多：多个用户级线程映射到较少或同样数量的内核级线程上
    - 中间结构：轻量级进程LWP，存在于用户级线程和内核级线程中间
      - LWP可共享所属进程的资源，同时还有自己的资源：TCB，栈，私有存储区
      - 每个LWP都和一个内核级线程相连
      - 用户级线程需要**访问内核时**，**线程库**会将其分配在LWP上运行，对于内核只能看见内核级线程和LWP两样东西

#### 7.3 线程同步锁

-  1.信号量  2.读写锁  3.互斥量  4.事件  5.临界区（Critical Section） 

### 8. 协程

-  协程是一种**比线程更加轻量级**的存在，正如一个进程可以有很多线程一样，一个线程也可以有很多协程，协程不被系统内核所管理，而**完全由程序**所控制，协程的开销远小于线程的开销 
- 线程中的多个协程以**串行**方式运行



### 9.锁

**互斥锁(** **mutexlock** **)：**

最常使用于**线程同步的锁**；标记用来保证在任一时刻，只能有一个线程访问该对象，同一线程多次加锁操作会造成死锁；临界区和互斥量都可用来实现此锁，通常情况下锁操作失败会将该线程睡眠等待锁释放时被唤醒

**自旋锁(spinlock)：**

同样用来标记只能有一个线程访问该对象，在同一线程多次加锁操作会造成死锁；使用硬件提供的swap指令或test_and_set指令实现；同互斥锁不同的是在锁操作需要等待的时候并不是睡眠等待唤醒，而是**循环检测保持者已经释放了锁**，这样做的好处是**节省**了线程从睡眠状态到唤醒之间内核会产生的消耗，在加锁时间短暂的环境下这点会提高很大效率

**读写锁(rwlock)：**

高级别锁，**区分读和写**，符合条件时允许多个线程访问对象。处于读锁操作时可以允许其他线程和本线程的读锁， 但不允许写锁， 处于写锁时则任何锁操作都会睡眠等待；常见的操作系统会在写锁等待时屏蔽后续的读锁操作以防写锁被无限孤立而等待，在操作系统不支持情况下可以用引用计数加写优先等待来用互斥锁实现。 读写锁适用于大量读少量写的环境，但由于其特殊的逻辑使得其效率相对普通的互斥锁和自旋锁要慢一个数量级；值得注意的一点是按POSIX标准 在线程申请读锁并未释放前本线程申请写锁是成功的，但运行后的逻辑结果是无法预测

**递归锁(recursivelock)：**

严格上讲递归锁只是**互斥锁的一个特例**，同样只能有一个线程访问该对象，但**允许同一个线程在未释放其拥有的锁时反复对该锁进行加锁操作**； **windows**下的**临界区**默认是**支持递归锁**的，而**linux下**的互斥量则需要设置参数PTHREAD_MUTEX_RECURSIVE_NP，**默认则是不支持**。 互斥量，临界区都可以为递归锁

**递归锁/非递归锁**

Mutex可以分为递归锁（recursive mutex）和非递归锁（non-recursive mutex）。 递归锁也叫可重入锁（reentrant mutex），非递归锁也叫不可重入锁（non-reentrant mutex）。

二者唯一的区别是：

同一个线程可以多次获取同一个递归锁，不会产生死锁。

如果一个线程多次获取同一个非递归锁，则会产生死锁

### 10. 补充

- 同步是直接制约，互斥是间接制约

## 三、存储器---内存

### 1.概述

#### 1.1 地址映射

- 虚地址---虚地址空间
  - 编译器对程序编译时使用虚地址，即相对起始地址0开始确定，这些地址构成虚地址空间
- 实地址---实地址空间
  - 程序在物理内存中的地址为实地址，这些地址构成实地址空间
- **地址重定位**：虚地址不能直接用来访问，需要转换成实地址
  - 虚地址----->实地址：由**硬件完成**

#### 1.2 程序的装入和链接

- 概述：源程序需要经过编译生成**若干目标模块**，这些模块都是从0开始的逻辑地址，然后将这些目标模块与所需要的**库模块**链接，生成一个可以装入内存执行的程序，并修改逻辑地址使之统一有序，执行前有**装入程序**将可执行程序装入内存并创建进程
- 链接方式
  - 静态链接：在装入内存执行前链接，不**能再拆分**成模块，**不能升级**模块，**不能共享**模块
  - 装入时动态链接： 边装入便链接，每次装入时重新链接，可以升级模块，但**不能共享**模块
  - 运行时动态链接：不链接，按模块装入，可以升级模块，可以共享模块
- 装入方式
  - 绝对装入：装入到**某个指定地址**，以后不能改变起始地址
  - 静态重定位装入：可装入内存**任意位置**，修改模块中各逻辑地址为实际物理地址，装入时一次性完成地址映射，以后不能再移动位置
  - 动态重定位装入：装入后仍然使用逻辑地址，当执行程序时再将模块的逻辑地址映射为物理地址，为提高效率需要专门的地址映射机构
- 静态库和动态库
  - 库：库函数，像printf的实现函数
  - 静态链接库：**编译**的时候将库函数连接到源代码上，可能造成代码冗余，但执行速度快
  - 动态链接库：编译的时候只是保存对应的库函数的地址，**执行**的时候再链接库函数，不用链接库节省内存，执行速度慢

### 2.连续存储器管理方式

#### 2.1 固定分区方式

- 将物理内存空间划分为大小，数量都固定的若干分区，按照进程的请求分配分区

- 分区大小一致导致进程最大尺寸固定，若进程尺寸过小导致**内部碎片**，降低内存利用率

#### 2.2 可变分区方式

- 分区大小，数量都可以变化，根据进程大小分配合适空间，产生**外部碎片**；分区回收时可以合并相邻空闲分区
- 分配算法
  - 首次适应算法
    - 从空闲分区链上逐个寻找尺寸合适的分区，若找到后就将该分区分配给进程，然后从下一个空闲分区开始找适合新进程的分区。循环的在空闲分区链上查找。
    - 会产生许多外部碎片，不容易满足大进程需要
    - 外部碎片：分区之间的小的分区空间
  - 最佳适应算法
    - 在空闲分区链上找尺寸和进程**最接近**的分区
    - 会产生许多外部碎片
    - 各空闲分区按照**由小到大**排序
  - 最坏适应算法
    - 在空闲分区链上找尺寸和进程**相差最大**的分区
    - 尽量使留下来的空闲分区空间较大
    - 各空闲分区按照**由大到小**排序
- 回收算法
  - 紧凑
    - 将各个进程移动到紧挨着另一个进程后面的空间 	

#### 2.3 覆盖技术

-  在单道连续分配中，当存储空间容不下程序时，可采用覆盖方法来解决；
- 覆盖基本思想：由于**程序运行时并非各个部分都要访问**，因此可以将用户空间分成**一个固定区**和**多个覆盖区**。将经常活跃的放入固定区，将那些将要用的段放入覆盖区，在需要时提前调入覆盖区，替换原有的段 

### 3.分页存储管理方式---离散，物理上分页

#### 3.1分页存储原理

- 页与页框

  - 页面------逻辑空间中
  - 页框，物理块号------物理空间中

- **逻辑地址 =  页号P + 页内地址d**

  - **页面大小**决定**页内地址d**的位数

  - **页号位数**决定**页面总数**

  - ```java
    若逻辑地址为32位，则逻辑地址空间大小为2的32次方即4GB。
    若页面大小为4KB即2的12次方，因为页面大小决定页内地址d的位数，所以低位0--11都为页内地址位。
    同时，其余12--31位为页号位数位，即地址空间中最多有2的20次方个页面。
    ```

  - 逻辑地址和物理地址的映射公式

    - **页号P = 【逻辑地址 / 页面大小】向下取整**
    - **页内地址d = 逻辑地址 % 页面大小**

- 页表

  - **每个进程**设置一个页号和物理块号的映射表称为页表，每个表项称做PTE
  - 页表存储在内存中，只存物理块号，页表按照页号的递增顺序排列；将页表的起始地址，长度保存在进程的页表寄存器PTR中

- 地址映射和越界保护

  - 地址映射由硬件完成，并不通过计算
    - **物理地址A = 页面所对应块号F × 页面大小L + 页内地址d**
  - 调度下一个进程时，根据页表寄存器PTR中页表起始地址和页表长度得出页号是否超过页表长度，若超过则越界

- 快表

  - 地址映射机构中具有并行查找能力的高速缓冲存储器，也就是**联想存储器TLB**
  - 只存储当前执行进程的部分页表，所以查快表比查页表快，每个快表项存储**页号及其对应物理块号**
  - 进行地址映射时首先访问快表，若找到就直接访问物理块，反之访问页表，并将其加入到快表中。加快进程访问内存速度

#### 3.2 两级和多级页表

- 页表过大时需要创建另一个页表叫目录表来存储原页表，目录表中存储原页表的物理块号，形成二级或多级页表
- 逻辑地址 = 外部页号P1 + 外部页内地址P2 + 页内地址d

### 4.分段存储管理方式---离散，逻辑上分块

- 段
  - 与页的区别：一个函数可能被放在多个页面，一个页面可能包含多个函数，而一段可以只是一个函数，段更适合升级和共享保护
  - 段：有逻辑意义的一组相关信息，各段长度不固定
  - 一个进程 = 主程序段 + 若干子程序段 + 数据段+堆栈段
- 逻辑地址 = 段号S + 段内地址d
  - 分段逻辑地址空间是**二维**的非线性地址空间
  - **段内地址d**的位数决定段的**最大长度**，而非段的长度
  - **段号S**的位数决定一个进程段的**最大数量**
- 段表
  - 分段以离散方式存储
  - 段表项 = 段号 + 段长 + 段基址
  - 段表在内存中的起始地址，长度保存在进程的段表寄存器中
- 地址映射和越界保护
  - 地址映射机构将段号和段表长度比较判断是否地址越界，然后判断段内地址是否不大于段长
- 段共享与保护
  - 设置共享段表





### 5.段页式存储管理方式---离散，逻辑分段，物理分页

- 概述
  - 先将进程按逻辑信息分成若干段，每一段按页面大小划分成若干页面
- 逻辑地址 =  段号S + 段内页号P + 页内地址d
  - 每个段有一个页表
- 地址映射和越界保护
  - 地址映射机构先判断段号是否不大于段表长度，然后判断段内页号和页表长度

### 6.虚拟存储系统

#### 6.1 概念

- 虚拟存储器：具有请求调入功能，置换功能，能够利用外存储器空余空间，从逻辑上对内存容量进行扩充的一种存储器系统
- 进程不再是一次性全部装入内存，也不是装入内存后一直驻留直到结束，而是利用时间和空间的局部性原理，某一段时间只装入进程中一部分程序
  - 进程一次性装入 --->   多次装入
  - 进程驻留  ----> 不断置换
- 虚存的最大容量： **Min(内存+外存，2^地址寄存器位数)** 

#### 6.2 请求分页存储管理方式---主流实现方式

6.2.1页表：进程在内外存之间换入换出的基本单位，实现页号和物理块好的映射

- 只有正在执行中的进程的页表驻留在内存中，其他进程的页表不必驻留在内存

- 页表项 =  页号 + 物理块号 + 状态位P + 访问字段A + 修改位M + 外存地址

6.2.2 缺页中断机构

- 保护中断现场 --> 分析中断原因--->转入中断处理程序  ---> 恢复中断

6.2.3 地址映射机构

6.2.4 抖动/颠簸：频繁缺页，导致频繁置换

- 原因
  - 置换策略失误
  - 运行进程太多
- 解决方法
  - 终止发生抖动进程
  - 增加物理内存容量

6.2.5 工作集

- 某时刻前最近访问过的页面集合（集合大小为工作集大小），去除掉集合中重复的页面
- 合适的工作集有利于防止抖动出现

6.2.6 调入页面策略

- 预调页面策略：一次调入若干页面，用于进程运行前的首次调用
- 请求调页策略：运行期间发现缺页时才调页
- 整体对换：依次将整个进程调入内存
- 部分兑换：按页，段将进程依次调入内存

6.2.7**页面置换算法**

- 最佳置换算法OPT
  - 淘汰未来永远不会访问，最长时间内不会访问的页面
  - 不能实现，用来做衡量标准
- 先进先出置换算法FIFO
  - 淘汰**最先调入**内存的页面
  - **Belady异常**：当分配给进程的内存块增加后，可能导致缺页次数增多
- 最近最久未使用置换算法**LRU**
  - 淘汰最近一段时间内**最久未被访问**的页面
- 最近最少使用置换算法**LFU**
  - 淘汰过去一段时间里**访问次数最少**的页面
- 时钟置换算法---最近未用置换算法**NRU**
  - 每个页面关联一个**访问位u**用来记录该页面过去一段时间被访问次数，一个**修改位m**用来记录该页面过去一段时间是否被修改
  - 先淘汰**um为00**的页面，若找不到，淘汰**um为01**的，若还没找到，则将所有页面的u置为0重新查找
- 页缓冲思想
  - **空闲页面链表**：所有**空白内存块**，未完成进程的的**未修改淘汰页所在内存块**组成
  - **修改页面链表**：所有未完成进程的**修改淘汰页所在内存块**组成
  - **缺页时**先查找上面这两个链表，若没找到，分配**空闲页面链表**的链首块给进程以装入所缺页面。
  - **淘汰时**根据淘汰页是否被修改来决定放在哪个链表末尾
  - 系统周期性将**修改页面链表**的多个页面清空





## 四、IO设备---除内外存和CPU外

### 1. 设备控制器

- 控制一个或多个I/O设备，它是CPU与I/O设备之间的接口，接受CPU命令，控制I/O设备
- 通过数据总线和CPU交换数据

### 2. I/O通道

- 概述
  - 当主机外设很多时，在设备控制器控制下还是会多次打断CPU，所以引入通道
  - 数据传输独立于CPU，不含存储器，包含CPU
- 通道程序
  - 通道通过执行通道程序和设备控制器共同实现对I/O设备的控制
  - 通道程序由一系列通道指令构成

### 3. I/O系统结构

- 总线型I/O系统结构
  - CPU和内存直接连接到总线上，I/O设备通过设备控制器连接到总线上
  - 设备-->控制器--->总线--->CPU和内存
  - 总线是各部件之间信息传送的一组公共通路
- 通道型I/O系统结构
  - 在CPU和设备控制器之间增加一层通道
  - 设备-->控制器--->I/0通道--->总线--->CPU和内存

### 4.I/O控制方式

- 轮询控制方式
- 中断驱动控制方式
- 直接存储器存取方式**DMA**：程序运行时，数据传送直接在设备与内存之间进行，开始和结束是才需要CPU干预
- 通道控制方式：以内存为中心，实现设备与内存直接进行数据交换的控制方式，**比DMA对CPU干预更少**

### 5. 设备驱动程序

- 接收上层软件的抽象I/O要求，驱动把要求转换成具体要求，发送给设备控制器

### 6.设备分配的数据结构

- 设备控制表DCT：OS为每个设备配置一张DCT表，记录设备特性
- 控制器控制表COCT：每个设备控制器配置一张COCT表，记录控制器信息
- 通道控制表CHCT：每个通道配置一张CHCT表，记录通道的信息
- 系统设备表SDT：**OS内只有一张SDT**，记录OS中所有物理设备的信息，每个设备占一个表项

### 7.SPOOLing 

- 将独占设备模拟成共享设备来使用，通过在**外存**上增加缓冲区实现

### 8. 补充

-  I/O交通管制程序的主要功能是管理设备、控制器和通道的状态信息 

## 五、文件---外存

- 文件属性：系统属性，只读属性，隐藏属性，归档属性

### 1.文件的逻辑结构

- 有结构文件
  - 顺序文件：
    - 串结构：如链表
    - 顺序结构：如数组
  - 索引文件：建立一张索引表，索引表按关键字排序；如根据学号查找信息
  - 索引顺序文件：将顺序文件中所有记录分成若干组，为这些组建立索引表
  - 直接文件：关键字和对应物理地址之间的对应关系，通过关键字直接找到物理地址
  - 散列文件：对关键字散列，hash值决定物理地址
- 无结构文件
  - 流式文件：字节流
    - 源程序文件

### 2.文件的物理结构

- 连续文件：  每个文件在磁盘中占用一组连续的块，可以方便的进行顺序访问和随机访问（可以直接算出逻辑块号对应的物理块号），但不方便文件拓展 

- 链接文件

  - 隐式链接：每个磁盘块的最后一个单元中设置一个链接指针指示下一个磁盘块的盘快号
  - 显示链接：各磁盘块的链接指针显式存放在外存的一张链接表中，称该表为文件分配表FAT，一个文件系统一张
  
- 索引文件

  - 单级索引：系统为每个文件建立一张索引表，每个逻辑块占一个表项，表项内容为该逻辑块对应的磁盘块号。索引表大小和磁盘块大小一致

  - 多级索引：单级索引的嵌套

    - ```java
    若磁盘块的大小为4KB，每个表项的大小为4B，那么一个索引块可以存放1000个磁盘块号地址，那么采用单级索引允许最大文件长度为1K*4KB=4MB，若采用二级索引允许最大文件长度为1K*1K*4KB=4GB
      ```

  - 混合索引

    - ```java
      一个长为13的地址索引表，其中0-9为直接地址，10为一级索引，11为二级索引，12为三级索引，若磁盘块的大小为4KB，每个表项的大小为4B，那么一个索引块可以存放1K个磁盘块号地址，10个直接地址对应10*4KB=40KB，一个一级索引对应1K*4KB=4MB，一个二级索引对应1K*1K*4KB=4GB，一个三级索引对应1K*1K*1K*4KB=4TB，则该文件系统允许最大文件长度为4TB+4GB+4MB+40KB
      ```

### 3.文件目录管理

- OS对文件目录管理要求
  - 按文件名存取
  - 提高检索速度
  - 允许文件重名
  - 允许文件共享

#### 3.1文件目录

- 文件控制快FCB
  - 一个文件 = 文件体 + 文件控制块FCB
  - 文件控制块FCB：文件的唯一标识，记录文件的属性
  - **文件目录**：一组文件控制块的有序集合，目录项不存储FCB的物理地址，存储的是实体
  
- 索引节点
  - 索引节点引入
    - 目录以前存储文件控制块，但检索文件时只用到了文件名这一项属性，所以将FCB中的文件名和其他属性分开存储，新的目录中的目录项存储**文件名**和指向其余信息的**指针**
  - 索引节点分类
    - 磁盘索引节点：存放在磁盘上，包含除文件名外所有FCB信息
    - 内存索引节点：存放在内存上，复制磁盘索引节点，外加若干状态信息
  
- 目录文件：存储该目录中所有子目录文件和数据文件的目录

  

#### 3.2 文件目录结构

- 单级目录结构：OS中只有一张目录表
- 两级目录结构：分为**主文件目录**和**用户文件目录**
  - 主文件目录：存储该系统中所有用户
  - 用户文件目录：存储不同用户对应的FCB
- 多级目录机构：树形目录

### 4.文件的存储空间管理

- 空闲表法：所有空闲分区建立一张空闲表，类比内存分配中的可变分区分配
- 空闲块链法：每个空闲磁盘块中存放一个指针，指向另一个空闲盘块
- 位示图法：利用二进制位来表示磁盘中一个盘块的使用情况，值为0，表示空闲，值为1，表示已分配
  - 空闲内存和空闲磁盘都可以用该方法
  - 开机之后常驻内存
- 成组链接法：UNIX采用该方法

### 5.文件共享

- 基于索引节点的共享方式----硬链接
  - 文件目录项 = 文件名 + 索引节点指针
  - 除文件主的其他用户只要将**索引节点指针指向共享的索引节点**即可实现共享
  - 存储共享文件的索引节点中有count变量来保存指向当前共享文件的用户数，当count=1时，文件主才能删除文件，否则不能删除。
  - 当不遵守规则删除共享文件时会出现悬空指针
- 利用符号链接实现共享----软链接
  - 在目录中新建一个目录项，创建一个符号链接的的新文件，该文件存储共享文件的**路径**
- 索引节点又名为inode，也可简称 i 节点
-  建立符号链接时，引用计数值直接复制；建立硬链接时，引用计数值加1。删除文件时，删除操作对于符号链接是不可见的，这并不影响文件系统，当以后再通过符号链接访问时，发现文件不存在，直接删除符号链接；但对于硬链接则不可以直接删除，引用计数值减1，若值不为0，则不能删除此文件，因为还有其他硬链接指向此文件。 

### 6.文件保护



### 7.磁盘调度

- 访问磁盘所需时间的影响因素
  - 寻道时间：最主要的因素
  - 磁盘旋转延迟
  - 数据传输时间

- 移臂调度算法
  - 先来先服务：按照访问磁盘的**先后次序**进行调度
  - 最短寻到时间有限：总是选择与磁头**当前所在磁道最近的**磁道访问请求
  - 扫描算法SCAN（电梯算法）：从**磁头当前移动方向上**选择与当前磁道**距离最近**的磁道访问请求
  - 循环扫描算法：**磁头单向移动**，如从外向里，到达最里层后马上返回最外层
  - N-Step-SCAN算法：将当前磁盘请求队列分成**若干长为N的子队列**，每个队列采用**SCAN算法**
  - FSCAN算法：将当前磁盘请求队列分成**两个子队列**，先用**SCAN算法**处理某一个，当有新的磁盘I/O请求时加入到另外一个队列中，处理完当前队列后再处理另一个队列

### 8.磁盘格式化

-  一个新的磁盘是一个空白版，必须分成扇区以便磁盘控制器能读和写，这个过程称为**低级格式化**（或物理格式化）。低级格式化为磁盘的每个扇区采用特别的数据结构，包括校验码。为了使用磁盘存储文件，操作系统还需要将自己的数据结构记录在磁盘上。这分为两步。**第一步**是将磁盘分为由一个或多个柱面组成的分区，每个分区可以作为一个独立的磁盘。在分区之后，**第二步**是逻辑格式化（创建文件系统）。在这一步，操作系统将初始的文件系统数据结构存储道磁盘上。这些数据结构包括空闲和已分配的空间和一个初始为空的目录。 

### 9.补充

-  SFT-1是低级磁盘容错技术，主要用于防止磁盘表面发生缺陷所引起的数据丢失；SFT-II是中级磁盘容错技术，主要用于防止磁盘驱动器和磁盘控制器故障所引起的系统不能正常工作；SFT-III是高级系统容错技术。 

## 六、 补充

- 1、总线的**带宽**（总线**数据传输速率**）

  总线的带宽指的是**单位时间内总线上传送的数据量**，即每秒钟传送MB的最大稳态[数据传输率]。与总线密切相关的两个因素是总线的位宽和总线的工作频率，它们之间的关系：

  **总线的带宽=总线的工作频率*总线的位宽/8**

  **或者总线的带宽=（总线的位宽/8）/总线周期**

  2、总线的**位宽**

  总线的位宽指的是总线能**同时传送的[二进制数据]的位数**，或数据总线的位数，即32位、64位等总线宽度的概念。总线的**位宽越宽，每秒钟数据传输率越大，总线的带宽越宽**。

  3、总线的**工作频率**

  总线的工作时钟频率以**MHZ**为单位，工作频率越高，总线**工作速度越快，总线带宽越宽**。

- **通常磁盘数据访问时间计算分为三个部分（实际上是四个，但是启动时间不加说明时忽略不计）：**

  - **寻道时间，也称寻找时间：磁头移动到指定磁道需要的时间**
  - **旋转延迟时间：磁头定位到某一磁道的扇区所需要的时间**
  - **传输时间：从磁盘读出或者写入经历的时间**、

- **SMP**：Symmetrical Multi-Processing，对称性多核处理器，多进程可以在不同的核上运行，但是线程不可以跨机器迁移，因为线程是存在于单一的进程之中，只能在一个核上运行 

- **处理器的寄存器**分为两种用户可见寄存器和控制和状态寄存器

  1.用户可见寄存器又分为

  - 数据寄存器（Data Register）：又称通用寄存器，用于各种算术逻辑指令和访存指令
  - 地址寄存器（Address Register）：用于存储数据及指令的物理地址、线性地址或者有效地址，用于某种特定方式的寻址
  - 条件码寄存器：保存处理器操作结果的各种标记位

  1. 控制和状态寄存器

  - 程序计数器（Program Counter，PC），记录了将要取出的指令的地址
  - 指令寄存器（Instruction Register，IR），存储正在执行的指令
  - 程序状态字（Program Status Word，PSW），记录了处理器的运行模式等。

- 堆中存储成员变量，栈中存储局部变量

  -  局部变量存放在栈中，堆中存放的是new和malloc开辟出的，而程序中定义的常量存放在只读存储区 

- CPU本身是用来计算的，所以主要由运算器、控制器构成。CPU是可剥夺资源，所以竞争CPU不会产生死锁

-  **可重入代码**(Reentry code)也叫纯代码(Pure code)是一种允许多个进程同时访问的代码。为了使各进程所执行的代码完全相同，故不允许任何进程对其进行修改。程序在运行过程中可以被打断，并由开始处再次执行，并且在合理的范围内（多次重入，而不造成堆栈溢出等其他问题），程序可以在被打断处继续执行，且执行结果不受影响 

- **系统总线**是微机中各插件板与系统板之间的总线，用于插件板一级的互连。

  - 串行通信接口**SCI**属于**内部总线**，一种通用一部通信接口UART。------**属于内部总线**
  - **PCI总线**属于**系统总线**，为显卡、声卡、网卡、MODEM等设备提供了连接接口
  - **ISA**总线标准是IBM公司为推出PC/AT机而建立的**系统总线**标准，对XT总线的扩展。
  - **VESA**总线是一种局部总线，简称为VL总线。它的推出为微机**系统总线**体系结构的革新奠定了基础。该总线系统考虑到CPU与主存和Cache 的直接相连，通常把这部分总线称为CPU总线或主总线，其他设备通过VL总线与CPU总线相连，所以VL总线被称为局部总线。
  
- 脏数据是啥？

  通俗的讲：**当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是脏数据，依据脏数据所做的操作可能是不正确的。**

  突然断电，或者内存足够大时脏数据可能不会被写入磁盘中

- 大端： 高位在前， 小端：低位在前

- 单缓冲：缓冲区只有一个位置； 双缓冲：缓冲区有两个位置

- 广义指令：可以被中断的程序段

-  Linux中的权限有r(读) w(写) x(执行)，分别用数字4,2,1代表。
  Umask是设置系统创建文件时的默认权限，是创建文件权限补码，对文件默认时666, 目录默认777 

  umask是从权限中“拿走”相应的位,且文件创建时不能赋予执行权限，减去umask的位就是结果。

- HANDLE hMutexSuicide=::OpenMutex (SYNCHRONIZE,FALSE,g_szMutexName);其中FALSE的作用是**不需要向下传递**

- Linux进程间通信：管道、信号、消息队列、共享内存、信号量、套接字(socket)

  Linux线程间通信：互斥量（mutex），信号量，条件变量

  Windows进程间通信：管道、消息队列、共享内存、信号量  （semaphore）  、套接字(socket)

  Windows线程间通信：互斥量（mutex），信号量（semaphore）、临界区（critical section）、事件（event）

- 1） 进程间通信方法有：文件映射、共享内存、匿名管道、命名管道、邮件槽、剪切板、动态数据交换、对象连接与嵌入、动态连接库、远程过程调用等

  （2） 事件、临界区、互斥量、信号量可以实现线程同步